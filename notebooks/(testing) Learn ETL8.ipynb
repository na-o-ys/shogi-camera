{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from IPython import display\n",
    "import numpy as np\n",
    "\n",
    "def display_image(arr):\n",
    "    b = BytesIO()\n",
    "    Image.fromarray(np.uint8(arr)).save(b, format='png')\n",
    "    data = b.getvalue()\n",
    "    display.display(display.Image(data=data, format='png', embed=True))\n",
    "\n",
    "IMG_ROWS = 64\n",
    "IMG_COLS = 64\n",
    "\n",
    "data = np.load(\"../data/etl8.npz\")['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sklearn.model_selection\n",
    "import keras\n",
    "\n",
    "NUM_CLASSES = 956\n",
    "\n",
    "# 150 ~ 159 for hyper parameters\n",
    "alldata = data[0:150]\n",
    "dataset_len = alldata.shape[0]\n",
    "\n",
    "# flatten\n",
    "x_all = alldata.reshape((dataset_len * NUM_CLASSES, IMG_ROWS, IMG_COLS, 1))\n",
    "x_all = x_all.astype(np.float32)\n",
    "x_all /= 255\n",
    "y_all = np.tile(np.arange(NUM_CLASSES), dataset_len)\n",
    "y_all = keras.utils.to_categorical(y_all, NUM_CLASSES)\n",
    "\n",
    "x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(x_all, y_all, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 29, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              4719616   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 956)               979900    \n",
      "=================================================================\n",
      "Total params: 6,841,788\n",
      "Trainable params: 6,841,788\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Input\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Sequential, Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "input_shape = (IMG_ROWS, IMG_COLS, 1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "        optimizer=keras.optimizers.Adadelta(),\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4033/4033 [==============================] - 122s - loss: 6.5122 - acc: 0.0036 - val_loss: 5.4651 - val_acc: 0.0215\n",
      "Epoch 2/20\n",
      "4033/4033 [==============================] - 121s - loss: 4.5825 - acc: 0.0715 - val_loss: 2.5347 - val_acc: 0.3805\n",
      "Epoch 3/20\n",
      "4033/4033 [==============================] - 121s - loss: 2.8691 - acc: 0.2803 - val_loss: 1.0727 - val_acc: 0.7195\n",
      "Epoch 4/20\n",
      "4033/4033 [==============================] - 121s - loss: 1.8967 - acc: 0.4799 - val_loss: 0.5391 - val_acc: 0.8567\n",
      "Epoch 5/20\n",
      "4033/4033 [==============================] - 121s - loss: 1.3761 - acc: 0.6088 - val_loss: 0.3284 - val_acc: 0.9042\n",
      "Epoch 6/20\n",
      "4033/4033 [==============================] - 121s - loss: 1.0693 - acc: 0.6926 - val_loss: 0.2126 - val_acc: 0.9394\n",
      "Epoch 7/20\n",
      "4033/4033 [==============================] - 121s - loss: 0.8749 - acc: 0.7445 - val_loss: 0.1670 - val_acc: 0.9534\n",
      "Epoch 8/20\n",
      "4033/4033 [==============================] - 121s - loss: 0.7415 - acc: 0.7833 - val_loss: 0.1679 - val_acc: 0.9492\n",
      "Epoch 9/20\n",
      "4033/4033 [==============================] - 121s - loss: 0.6501 - acc: 0.8100 - val_loss: 0.1266 - val_acc: 0.9619\n",
      "Epoch 10/20\n",
      "4033/4033 [==============================] - 121s - loss: 0.5812 - acc: 0.8289 - val_loss: 0.1242 - val_acc: 0.9630\n",
      "Epoch 11/20\n",
      "4033/4033 [==============================] - 121s - loss: 0.5265 - acc: 0.8460 - val_loss: 0.1239 - val_acc: 0.9635\n",
      "Epoch 12/20\n",
      "4033/4033 [==============================] - 121s - loss: 0.4908 - acc: 0.8569 - val_loss: 0.0978 - val_acc: 0.9710\n",
      "Epoch 13/20\n",
      "4033/4033 [==============================] - 121s - loss: 0.4618 - acc: 0.8650 - val_loss: 0.0794 - val_acc: 0.9766\n",
      "Epoch 14/20\n",
      "4033/4033 [==============================] - 121s - loss: 0.4331 - acc: 0.8734 - val_loss: 0.0723 - val_acc: 0.9787\n",
      "Epoch 15/20\n",
      "4033/4033 [==============================] - 121s - loss: 0.4100 - acc: 0.8797 - val_loss: 0.0694 - val_acc: 0.9802\n",
      "Epoch 16/20\n",
      "4033/4033 [==============================] - 122s - loss: 0.3944 - acc: 0.8858 - val_loss: 0.0815 - val_acc: 0.9770\n",
      "Epoch 17/20\n",
      "4033/4033 [==============================] - 122s - loss: 0.3794 - acc: 0.8900 - val_loss: 0.0672 - val_acc: 0.9805\n",
      "Epoch 18/20\n",
      "4033/4033 [==============================] - 122s - loss: 0.3723 - acc: 0.8931 - val_loss: 0.0631 - val_acc: 0.9808\n",
      "Epoch 19/20\n",
      "4033/4033 [==============================] - 122s - loss: 0.3657 - acc: 0.8951 - val_loss: 0.0699 - val_acc: 0.9782\n",
      "Epoch 20/20\n",
      "4033/4033 [==============================] - 122s - loss: 0.3557 - acc: 0.8983 - val_loss: 0.0653 - val_acc: 0.9814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0c6ac64f98>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import Callback, EarlyStopping\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=12,\n",
    "    zoom_range=[0.9, 1.5],\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    fill_mode=\"constant\",\n",
    "    cval=0.0\n",
    ")\n",
    "BATCH_SIZE = 32\n",
    "steps = int(x_train.shape[0] / BATCH_SIZE)\n",
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=BATCH_SIZE),\n",
    "        steps_per_epoch=steps, epochs=50, verbose=True,\n",
    "        callbacks=[EarlyStopping(patience=4)],\n",
    "        validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.predict(x_test)\n",
    "# predicted = np.array([np.argmax(r) for r in score])\n",
    "predicted = np.argmax(score, axis=1)\n",
    "\n",
    "idx, val = np.where(y_test == 1)\n",
    "ans = val[idx]\n",
    "\n",
    "correct = np.where(predicted == ans)[0]\n",
    "errors = np.where(predicted != ans)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267\n",
      "14073\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAAAAACPAi4CAAADkElEQVR4nO2W23PaRhTGP61uIHBk\nrmM3E19KkrppUyeZ9qnTvvXf7kzf2pm4mUw7ruPExhBjU0AChISQtKvtg7ADYjHM9Kkdn7fds99P\nh92z3wLcx33cx38oNF1amiNr6MnBj/l/BYBZKyzNKWvoZRpsMpkPRqLk8h93Ky/Xnm10CHf/OOfr\nVCAXXX92bBy+yKjoXw+GI5F+EaAcDt5GM2N9Z/JL8eCvC6FaBAibz9uXM+PBz0brqect0y+eAr8a\nV+TZcbdBpcBPL1sOgG+bqbKI7lOo1dyaADbMb6TWaA5F7tWu8MQEjdRXTUm6XaxpIOw6gqyauiJA\nCBpphOJF2TxjAAD1sHDkTFw9t1fKboTHnTsBUrLVMTNl/pTVYwBgkx3puLJt5LTMeOwI9nIGoD3u\nWBwAAgq7s2f3AVIwH5HyT9qo3yrt1d/QRf0sIDarv/lIuptefFsZcFS+z2uZXr3XC6KXj0Yi/SyA\nXn63VQdAZApYdrUeofcrpJfj3yeAnu/aIv3cKXSHu2oCjcH+zmQBdnXV6w8YAF21hysBQUvRAPCY\nAeBykuJcBYCy0YkW1SkAt6QKABXDGPpD10smiS4B6rbfjlcC4MUKAJn6Mar6SfJFiVEA+ULLEern\nAaFXUoCsQpEpvp/uGXVkCfI+vRAXMA+g/UqZQJdjSPXL6QWOJ0RHpdJwxfrUXXBzL3TIsQffuTUA\ny8vkHrvNJQWk7kL/4ziUiwhn55xj/kx94y3RpwDj12C6Ec3ZT8yelD6EplqosGOBL6duYwgohiOR\n24IlPf/1EyZvlzBh3bVcGWbe+co+5wDUB9nNfDVnUqvbtyyfRSsu0zR0YrGa0wWw/QMZW3aQpSfn\nFGu7MlTWc7devbYA+0ga2PSh2mpEyBoDJgQsWBrRgrF/aj7XAPfdyXXAwnF3ApQOt8SP2CKAdCPe\nfVeuSQDnADD0AbQbn1WFD/EiQPUo6FmvdvOiK+EEAG3Y+1VRDQsAVesxwD1yvtSSBUoYAAC9Yl9s\npBeLADnVAwD3zKwCAORclDSFf8o+F3h4GkAKvg8AvH2qEABQNH/aVU7dMFcD9F038QH28TIGgA35\npn95Z7ifXQkwMJp+MKYAQDJecJOLmvpBZhVg0+3NjWWTfmogr7nzjXY3IL/lhvMz3P3kBHG7+cBI\nAeb3lewUz9POMXv40Z/ZpcaQRGFPTVVo6ncr0rH6X9t9/B/jH/SAdUAaw8ahAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAAAAACPAi4CAAAC/UlEQVR4nO2Wy2/TQBCHf7vrteO8\nQ5oSCi2liLZq4cYBJA78/VwAVagqVK3aRJQmfShpHnbs3eWQtHYmcdKIE1LmEnk8+3leOxNgKUtZ\nyuOEs9mv555/Xf03gKgWFwGwtCAGTA0WAcjdFWogzCIAXsoQAyPtRQAm0NRCOzPzRD3IuPS8Ti8C\nAFMU4NuLAIyaaBtG6zITIHM053POU4ATehRgaQBgSQ1tkWczBnBKrPCK3TUC207XbucDmJFWEFcU\n3rpOpluuWBq53nxAeq2mwrGYrr8g9en0iHMhPibUIg6o7F12fQdIsf5Io9rQutMD4PoJgJiaFf1A\nmTT4zvtY9xqlAUD7CVciBpDl377RAtorl2KAYXObcKLHJwB2qmMQArjQ1aho0tYAIFzaopOAsrgF\n4wroXdhR94jhPBC2Px0QS6LreWB2CISHIvqcNcrBdX/iLAFYxUYAZjSATtwgO/xlCR5EIdiZtgIC\namdbIQAYf5hEzlP5sQkTeVCwW4C5v85cGsE5fKRS5S4T3A2esNAtOpKnra/1aQBW6XcBMZoe1nbV\n4UKHSj+tfNgxiqX5Ded9v9fn/W5rqgdu9XwAsMFwBquml7cGWglplRpN7843YcC0ChRAGioK4bZh\nAM0cAIBpXo3Um5mDCzNjMD8A+gc+ABPI0fP9GREm9eBQHqpgPANA9SQxyFR3Zs51OhMtMpWZZJtb\ns6YqXW3Z1LhC5urnW88WANARx2Xtm9lNPxowUSUpW+1f2ZfJo5l80XjBuKJstfSp/aJbS6ok9UCQ\nKmR9D+qss19CgtAckGd7rR0AvRO2T3dmAsAgNbZBVnJ1BZjmYWmbpnckRK1Dm8Wi5euDKwDQ9fwb\n73jqUKOAgeCxzs2s1oabKji21/2zaYkkIeib+Hpmz835CNf9cblRnbYfaQ5CJ1byzOrPh7vfO27u\nrU0h0NSE8XfbwVkUd//Eeaf/TERBAfXWw786tlH5Hp+Q/pHONxK2Q0wiLwuf9whe0rs+W9zVxeyX\n8h/LX+IDE9689Vq+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(len(errors))\n",
    "# print(len(correct))\n",
    "# e = errors[21]\n",
    "# display_image((x_test[e] * 255).reshape(IMG_ROWS, IMG_COLS))\n",
    "# display_image(data[0][predicted[e]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"../etl8_neru.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9560/9560 [==============================] - 2s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.037958197186410692, 0.9873430962343096]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaldata = data[150:]\n",
    "dataset_len = evaldata.shape[0]\n",
    "\n",
    "# flatten\n",
    "x_eval = evaldata.reshape((dataset_len * NUM_CLASSES, IMG_ROWS, IMG_COLS, 1))\n",
    "x_eval = x_eval.astype(np.float32)\n",
    "x_eval /= 255\n",
    "y_eval = np.tile(np.arange(NUM_CLASSES), dataset_len)\n",
    "y_eval = keras.utils.to_categorical(y_eval, NUM_CLASSES)\n",
    "\n",
    "model.evaluate(x_eval, y_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
